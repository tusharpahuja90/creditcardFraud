{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "------------\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# reading data from CSV file. \n",
    "# reading credit card data into pandas dataframe.\n",
    "bankdata = pd.read_csv(\"./creditcard.csv\")  \n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(bankdata.shape)  \n",
    "print(\"------------\")\n",
    "\n",
    "print(bankdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbeer of non-fraud transaction : 284315\n",
      "Numbeer of fraud transaction : 492\n",
      "Normal transacations:  99.82725143693798 %\n",
      "Fraud transacations 0.1727485630620034 %\n"
     ]
    }
   ],
   "source": [
    "countnf = len(bankdata[bankdata[\"Class\"]==0]) \n",
    "countf = len(bankdata[bankdata[\"Class\"]==1]) \n",
    "print(\"Numbeer of non-fraud transaction :\",countnf)\n",
    "print(\"Numbeer of fraud transaction :\",countf)\n",
    "percentnf = countnf/(countnf+countf)\n",
    "print(\"Normal transacations: \",percentnf*100,\"%\")\n",
    "percentf= countf/(countnf+countf)\n",
    "print(\"Fraud transacations\",percentf*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number: 1\n",
      "Training data:  (270566, 30)\n",
      "Testing data:  (14241, 30)\n",
      "test_sz 0.05\n",
      "Accuracy: 99.9157362544765 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14209\n",
      "           1       0.83      0.78      0.81        32\n",
      "\n",
      "    accuracy                           1.00     14241\n",
      "   macro avg       0.92      0.89      0.90     14241\n",
      "weighted avg       1.00      1.00      1.00     14241\n",
      "\n",
      "confusion_matrix:\n",
      " [[14204     5]\n",
      " [    7    25]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "193572       0          0\n",
      "154839       0          0\n",
      "245371       0          0\n",
      "141313       0          0\n",
      "187929       0          0\n",
      "\n",
      "[14241 rows x 2 columns]\n",
      "Precision:  83.33333333333334 % Recall:  78.125 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 2\n",
      "Training data:  (256326, 30)\n",
      "Testing data:  (28481, 30)\n",
      "test_sz 0.1\n",
      "Accuracy: 99.91924440855307 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28426\n",
      "           1       0.79      0.80      0.79        55\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.89      0.90      0.90     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "confusion_matrix:\n",
      " [[28414    12]\n",
      " [   11    44]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "240010       0          0\n",
      "136625       0          0\n",
      "273822       0          0\n",
      "137627       0          0\n",
      "121033       0          0\n",
      "\n",
      "[28481 rows x 2 columns]\n",
      "Precision:  78.57142857142857 % Recall:  80.0 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 3\n",
      "Training data:  (242085, 30)\n",
      "Testing data:  (42722, 30)\n",
      "test_sz 0.15000000000000002\n",
      "Accuracy: 99.9157342821029 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42648\n",
      "           1       0.75      0.77      0.76        74\n",
      "\n",
      "    accuracy                           1.00     42722\n",
      "   macro avg       0.87      0.88      0.88     42722\n",
      "weighted avg       1.00      1.00      1.00     42722\n",
      "\n",
      "confusion_matrix:\n",
      " [[42629    19]\n",
      " [   17    57]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "189242       0          0\n",
      "232656       0          0\n",
      "174418       0          0\n",
      "98354        0          0\n",
      "186302       0          0\n",
      "\n",
      "[42722 rows x 2 columns]\n",
      "Precision:  75.0 % Recall:  77.02702702702703 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 4\n",
      "Training data:  (227845, 30)\n",
      "Testing data:  (56962, 30)\n",
      "test_sz 0.2\n",
      "Accuracy: 99.91924440855307 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56861\n",
      "           1       0.77      0.78      0.77       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.88      0.89      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "confusion_matrix:\n",
      " [[56837    24]\n",
      " [   22    79]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "236778       0          0\n",
      "127073       0          0\n",
      "208502       0          0\n",
      "263323       0          0\n",
      "246221       0          0\n",
      "\n",
      "[56962 rows x 2 columns]\n",
      "Precision:  76.69902912621359 % Recall:  78.21782178217822 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 5\n",
      "Training data:  (213605, 30)\n",
      "Testing data:  (71202, 30)\n",
      "test_sz 0.25\n",
      "Accuracy: 99.91573270413753 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71082\n",
      "           1       0.75      0.76      0.75       120\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.87      0.88      0.88     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "confusion_matrix:\n",
      " [[71051    31]\n",
      " [   29    91]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "52247        0          0\n",
      "247905       0          0\n",
      "78338        0          0\n",
      "246056       0          0\n",
      "40618        0          0\n",
      "\n",
      "[71202 rows x 2 columns]\n",
      "Precision:  74.59016393442623 % Recall:  75.83333333333333 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 6\n",
      "Training data:  (199364, 30)\n",
      "Testing data:  (85443, 30)\n",
      "test_sz 0.3\n",
      "Accuracy: 99.92977774656788 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.82      0.76      0.79       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.88      0.89     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "confusion_matrix:\n",
      " [[85272    24]\n",
      " [   36   111]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "208059       0          0\n",
      "260930       0          0\n",
      "75125        0          0\n",
      "37292        0          0\n",
      "240913       0          0\n",
      "\n",
      "[85443 rows x 2 columns]\n",
      "Precision:  82.22222222222221 % Recall:  75.51020408163265 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 7\n",
      "Training data:  (185124, 30)\n",
      "Testing data:  (99683, 30)\n",
      "test_sz 0.35\n",
      "Accuracy: 99.9127233329655 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99513\n",
      "           1       0.74      0.75      0.74       170\n",
      "\n",
      "    accuracy                           1.00     99683\n",
      "   macro avg       0.87      0.87      0.87     99683\n",
      "weighted avg       1.00      1.00      1.00     99683\n",
      "\n",
      "confusion_matrix:\n",
      " [[99469    44]\n",
      " [   43   127]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "262609       0          0\n",
      "86834        0          0\n",
      "109268       0          0\n",
      "25634        0          0\n",
      "83745        0          0\n",
      "\n",
      "[99683 rows x 2 columns]\n",
      "Precision:  74.26900584795322 % Recall:  74.70588235294117 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 8\n",
      "Training data:  (170884, 30)\n",
      "Testing data:  (113923, 30)\n",
      "test_sz 0.39999999999999997\n",
      "Accuracy: 99.91661034207316 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    113724\n",
      "           1       0.76      0.76      0.76       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.88      0.88      0.88    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "confusion_matrix:\n",
      " [[113676     48]\n",
      " [    47    152]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "34342        0          0\n",
      "247348       0          0\n",
      "209920       0          0\n",
      "81451        0          0\n",
      "242321       0          0\n",
      "\n",
      "[113923 rows x 2 columns]\n",
      "Precision:  76.0 % Recall:  76.38190954773869 %\n",
      "-----------------------\n",
      "\n",
      "Iteration number: 9\n",
      "Training data:  (156643, 30)\n",
      "Testing data:  (128164, 30)\n",
      "test_sz 0.44999999999999996\n",
      "Accuracy: 99.91963421865735 %\n",
      "Classification Stats:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    127946\n",
      "           1       0.77      0.75      0.76       218\n",
      "\n",
      "    accuracy                           1.00    128164\n",
      "   macro avg       0.89      0.87      0.88    128164\n",
      "weighted avg       1.00      1.00      1.00    128164\n",
      "\n",
      "confusion_matrix:\n",
      " [[127898     48]\n",
      " [    55    163]] \n",
      "\n",
      "        Actual  Predicted\n",
      "183484       0          0\n",
      "255448       0          0\n",
      "244749       0          0\n",
      "63919        0          0\n",
      "11475        0          0\n",
      "...        ...        ...\n",
      "51556        0          0\n",
      "266130       0          0\n",
      "93717        0          0\n",
      "217714       0          0\n",
      "95021        0          0\n",
      "\n",
      "[128164 rows x 2 columns]\n",
      "Precision:  77.25118483412322 % Recall:  74.77064220183486 %\n",
      "-----------------------\n",
      "\n",
      "The best ratio is  70.0 :  30.0  with accuracy of  99.92977774656788\n"
     ]
    }
   ],
   "source": [
    "X = bankdata.drop('Class', axis=1)  \n",
    "y = bankdata['Class']  \n",
    "\n",
    "# the final preprocessing step is to divide data into training and test sets\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "i=1\n",
    "x=0.05\n",
    "test_sz=.00\n",
    "ax=0\n",
    "bestax = 0\n",
    "besty=0 \n",
    "for i in range(1,10):\n",
    " print(\"Iteration number:\",i)\n",
    " X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.00+x, random_state=0)\n",
    " print('Training data: ',X_train.shape)\n",
    " print('Testing data: ',X_test.shape)\n",
    " test_sz=0+x\n",
    " x=x+0.05\n",
    " #print(\"test_size=\",test_size)\n",
    " print(\"test_sz\",test_sz)\n",
    " #print(\"x=\",x)\n",
    " '''os = SMOTE(sampling_strategy=0.33, random_state=0)\n",
    " osX,osy=os.fit_sample(X_train,y_train)\n",
    " osX = pd.DataFrame(data=osX,columns=X_train.columns )\n",
    " osy= pd.DataFrame(data=osy,columns=[\"Class\"])\n",
    " print(\"length of oversampled data is \",len(osX))\n",
    " print(\"Number of normal transcation in oversampled data\",len(osy[osy[\"Class\"]==0]))\n",
    " print(\"No.of fraud transcation\",len(osy[osy[\"Class\"]==1]))\n",
    " print(\"Proportion of Normal data in oversampled data is \",len(osy[osy[\"Class\"]==0])/len(osX))\n",
    " print(\"Proportion of fraud data in oversampled data is \",len(osy[osy[\"Class\"]==1])/len(osX))\n",
    "\n",
    " osX[\"Normalized Amount\"] = RobustScaler().fit_transform(osX['Amount'].values.reshape(-1, 1))\n",
    " osX[\"Normalized Time\"] = RobustScaler().fit_transform(osX['Time'].values.reshape(-1, 1))\n",
    " osX.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n",
    " #print(osX)\n",
    " X_test[\"Normalized Amount\"] = RobustScaler().fit_transform(X_test['Amount'].values.reshape(-1, 1))\n",
    " X_test[\"Normalized Time\"] = RobustScaler().fit_transform(X_test['Time'].values.reshape(-1, 1))\n",
    " \n",
    " X_test.drop([\"Time\",\"Amount\"],axis=1,inplace=True)'''\n",
    " #print(X_test)\n",
    "# Training the Algorithm. Here we would use DecisionTreeClassifier\n",
    " from sklearn.tree import DecisionTreeClassifier  \n",
    " classifier = DecisionTreeClassifier()  \n",
    "# type your code here\n",
    " #classifier.fit(osX,osy)#(remove '#' for using over sampling)\n",
    " classifier.fit(X_train,y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    " y_pred=classifier.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluating the Algorithm\n",
    "# type your code here\n",
    " from sklearn.metrics import accuracy_score\n",
    " from sklearn.metrics import classification_report\n",
    " \n",
    " ax= float(accuracy_score(y_test, y_pred))*100\n",
    " print('Accuracy:', ax,'%')\n",
    "# SYNTAX: accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)\n",
    "\n",
    " print('Classification Stats:')\n",
    " print(classification_report(y_test, y_pred)) # precision means \n",
    "\n",
    " from sklearn.metrics import recall_score,classification_report, accuracy_score, precision_score,confusion_matrix\n",
    " print(\"confusion_matrix:\\n\",confusion_matrix(y_test, y_pred),\"\\n\")\n",
    " daf=pd.DataFrame({'Actual':y_test,'Predicted':y_pred})\n",
    "\n",
    " print(daf)  \n",
    " #print(\"Recall: \",float(recall_score(y_test, y_pred))*100, '%')\n",
    " print(\"Precision: \",float(precision_score(y_test, y_pred))*100, '%',\"Recall: \",float(recall_score(y_test, y_pred))*100, '%')\n",
    " print(\"-----------------------\\n\")\n",
    " if ax > bestax:\n",
    "    bestax = ax\n",
    "    besty = test_sz\n",
    "\n",
    "print(\"The best ratio is \", 100-besty*100, \": \", besty*100, \" with accuracy of \", bestax)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
